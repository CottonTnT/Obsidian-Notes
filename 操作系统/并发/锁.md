# 1 实现一个锁


- 需要获得什么硬件支持
- 需要获得什么操作系统的支持


## 1.1 评价锁
- 互斥，能否阻止多个线程进入临界区
- 公平性(fariness), 能否保证一个等待的线程会进入临界区，不会饿死
- 性能， 是使用锁之后增加的时间开销。一种是没有竞争的情况，即只有一个线程抢锁、释放锁的开支如何？另外一种是 一个 CPU 上多个线程竞争，性能如何？最后一种是多个 CPU、多个线程竞争时的性能。通 过比较不同的场景，我们能够更好地理解不同的锁技术对性能的影响


## 1.2 锁的演化



### 1.2.1 硬件原语的支持
#### 1.2.1.1 单处理器时代
>最早提供的互斥解决方案之一，就是在临界区关闭中断。

```c
void lock(){
	DisableInterupts();
}
void unlock(){
	 EnableInterupts();
}
```


缺点如下:

- 一个贪婪的程序可能在它开始时就调用 lock()，从而独占处理器。更糟的情况是，恶意程序调用 lock()后，一直死循环。后一种情况，系统无法重新获得控制，只能重启系统。关闭中断对应用要求太多，不太适合作 为通用的同步解决方案。
- 这种方案不支持多处理器。如果多个线程运行在不同的 CPU 上，每个线程都试 图进入同一个临界区，关闭中断也没有作用。线程可以运行在其他处理器上，因此能够进入临界区。多处理器已经很普遍了，我们的通用解决方案需要更好一些

- 第三，关闭中断导致中断丢失，可能会导致严重的系统问题。假如磁盘设备完成了读 取请求，但 CPU 错失了这一事实，那么，操作系统如何知道去唤醒等待读取的进程
- 第四，效率低，现代cpu对于关闭和打开中断的代码执行慢

#### 1.2.1.2 test-and-set

因为关闭中断的方法无法工作在多处理器上，所以系统设计者开始让硬件支持锁.最简单的硬件支持是测试并设置指令（test-and-set instruction），也叫作原子交换（atomic exchangeoh）

在`x86`上是`xchg`指令,效果如下

```c
int TestAndSet(int *old_ptr, int new){
	int old = *old_ptr;
	*old_ptr = new;
	return old;
}

//x86还有一种Compare-and-Swap
int CompareAndSwap(int *ptr, int expected, int new){
	int actual = *ptr;
	if(actual == expected){
		*ptr = new;
	}
	return actual;
}
```

简单的自旋锁如下
```c
typedef struct lock_t{
	int flag;
}lock_t;

void init(lock_t* lock){
	lock->flat = 0;
}

void lock(lock_t* lock){
	while(TestAndSet(lock, 1) == 1){
			//spin-wait(do nothing);
	}
}

void unlock(lock_t* lock){
	lock->flag = 0;
}
```


- 在单处理器上，需要抢占式的调度器（preemptive scheduler，即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法 使用，因为一个自旋的线程永远不会放弃 CPU。


#### 1.2.1.3 fetch-and-add

（fetch-and-add）指令，它能原子地 返回特定地址的旧值，并且让该值自增一。获取并增加的 C 语言伪代码如下

```cpp
int FetchAndAdd(int *ptr){
	int old = *ptr;
	*ptr = old + 1;
	return old;
}

typedef struct lock_t{
	int ticket;
	int turn;
}lock_t;


void lock_init(lock_t *lock){
	lock->ticket = 0;
	lock>turn = 0;
}

void lock(lock_t *lock){
	int myturn  = FetchAndAdd(&lock->ticket);
	while(lock->turn != myturn)
		;//spin
}
void unlock(lock_t *lock){
	FetchAndAdd(&lock->turn);
}
```
- ticket 作为该线程的“turn”顺位，即第几顺位获取锁

- *能够保证所有线程都能抢到锁*



#### 1.2.1.4 评价自旋锁

- 正确性:自旋锁一次只允许一个线程进入临界区。因此，这是正确的锁。
- 公平性:test-and-set不提供，fetch-and-add提供
- 性能:在单 CPU 的情况下，性能开销相当大。假设一个线程持有锁进入临界区 时被抢占。调度器可能会运行其他每一个线程（假设有 N−1 个这种线程）。而其他线程都在 竞争锁，都会在放弃 CPU 之前，自旋一个时间片，浪费 CPU 周期。 但是，在多 CPU 上，自旋锁性能不错（如果线程数大致等于 CPU 数）。假设线程 A 在 CPU 1，线程 B 在 CPU 2 竞争同一个锁。线程 A（CPU 1）占有锁时，线程 B 竞争锁就会自 旋（在 CPU 2 上）。然而，临界区一般都很短，因此很快锁就可用，然后线程 B 获得锁。自 旋等待其他处理器上的锁，并没有浪费很多 CPU 周期，因此效果不错


要解决的浪费的时间片，如单`cpu`多线程竞争一个锁,我们还需要操作系统的支持


### 1.2.2 操作系统原语的支持

硬件支持让我们有了很大的进展：我们已经实现了有效、公平（通过 ticket 锁）的锁。 但是，问题仍然存在：如果临界区的线程发生上下文切换，其他线程只能一直自旋，等待 被中断的（持有锁的）进程重新运行。有什么好办法？

#### 1.2.2.1 简单让出cpu

线程可以处于 3 种状态之一（运行、就绪和阻塞）。
在这种方法中，*我们假定操作系统提供原语 yield()*，线程可以调用它主动放弃 CPU， 让其他线程运行。yield()系统调用能够 让运行（running）态变为就绪（ready）态，从而允许其他线程运行。因此，让出线程本质上取消调度（deschedules）了它自己。 

考虑在单 CPU 上运行两个线程。在这个例子中，基于 yield 的方法十分有效。一个线程调用 lock()，发现锁被占用时，让出 CPU，另外一个线程运行，完成临界区。在这个简单的 例子中，让出方法工作得非常好。 现在来考虑许多线程（例如 100 个）反复竞争一把锁的情况。在这种情况下，一个线 程持有锁，在释放锁之前被抢占，其他 99 个线程分别调用 lock()，发现锁被抢占，然后让 出 CPU。假定采用某种轮转调度程序，这 99 个线程会一直处于运行—让出这种模式，直到 持有锁的线程再次运行。虽然比原来的浪费 99 个时间片的自旋方案要好，但这种方法仍然成本很高，*上下文切换的成本*是实实在在的，因此浪费很大。 更糟的是，我们还没有考虑饿死的问题。一个线程可能一直处于让出的循环，而其他 线程反复进出临界区。很显然，我们需要一种方法来解决这个问题。


#### 1.2.2.2 使用队列：休眠代替自旋

前面一些方法的真正问题是存在太多的偶然性。调度程序决定如何调度。如果调度不合理，线程或者一直自旋（第一种方法），或者立刻让出 CPU（第二种方法）。无论哪种方法，都可能造成浪费。 因此，我们必须*显式地施加某种控制，决定锁释放时，谁能抢到锁*。为了做到这一点， 我们需要操作系统的更多支持，并需要一个队列来保存等待锁的线程。

- 利用`Solaris`提供的支持，它提供了两个调用:
	- `park()`能够让调用线程休眠
	- `unpard(threadID)`则会唤醒`threadID`标识的线程

```c
typedef struct lock_t{
	int flag;
	int guard;
	queue_t *q;
}lock_t;

void lock_init(lock_t *m){
	m->flag = 0;
	m->guard = 0;
}

void lock(lock_t *m){
	while(TestAndSet(&m->guard, 1) == 1){
		//acquire guard lock by spinning
	}
	if(m->flag == 0){
		m->flag = 1;//lock is aquired
		m->guard = 0;
	}else{
		queue_add(m->q, gettid());
		m->guard = 0;
		park();//有风险
//如果不凑巧，一个 线程将要 park，假定它应该睡到锁可用时。这时切换到另一个线程（比如持有锁的线程）， 这可能会导致麻烦。比如，如果该线程随后释放了锁。接下来第一个线程的 park 会永远睡 下去（可能）。
	}
}

//


void unlock(lock_t *m){
	while(TestAndSet(&m->guard, 1) == 1){
		;//acquire guard lock by spinning
	}
	if(queue_empty(m->q))
		m->flag = 0; //let go of lock , no one wants it
	else
		unpark(queue_remove(m->q)); //hold lock(for next thread!)
	m->guard = 0;
}

//Solaris 通过增加了第三个系统调用 se7park()来解决这一问题。通过 setpark()，一个线程 表明自己马上要 park。如果刚好另一个线程被调度，并且调用了 unpark，那么后续的 park 调用就会直接返回，而不是一直睡眠。lock()调用可以做一点小修改
queue_add(m->q,gettid());
m->guard = 0;
setpark();
```

- `Linux`提供了`futex`，但提供更多的内核功能,具体来说， *每个 `futex` 都关联一个特定的物理内存位置，也有一个事先建好的内核队列*。调用者通过 `futex` 调用（见下面的描述）来睡眠或者唤醒

	- `futex_wait(address, expexted)`,如果`address`处的值等于`expected`就会让调用线程睡眠,否则立刻返回
	- `futex_wake(address)`唤醒队列中的一个线程

	
```c

void mutex_lock(int *mutex){
	int v;
/* Bit 31 was clear, we got the mutex(this is the fastpath) */
	if (atomic_bit_test_set(mutex, 31) == 0)
		return;
	atomic_increment(mutex);
	while(1){
		if(atomic_bit_test_set(mutex, 31) == 0){
			atomic_decrement(mutex);
			return;
		}
		/* We have to wait now.First make sure the futex value
		we are monitoring is truly negative(i.e. locked). */
		v = *mutex;
		if(v >= 0)
			continue;
		futex_wait(mutex, v);
	}
}

void mutex_unlock(int *mutex){
	/* Adding 0x80000000 to the counter results in 0 if and only if there not
	other interested threads */
	if(atomic_add_zero(mutex, 0x80000000))
		return;
	/* there are other threads waiting 
}
```







