>[!definion] 什么是 `CPU`缓存一致性问题
CPU 缓存一致性（Cache Coherence）问题指 CPU Cache 与内存的不一致性问题。事实上， 在分析缓存一致性问题时，考虑 L1 / L2 / L3 的多级缓存没有意义， **所以只考虑缓存一致性抽象模型，只考虑核心独占的缓存。**


# 1 纵向：Cache 与 内存的一致性问题


  `Cache` 的读取过程会受到 `Cache` 的写入策略影响, 直接讨论 `Cache` 不同的写入策略

## 1.1 写直达策略(write through)


在每次写入操作中，同时修改 `Cache` 数据和内存数据，始终保持 `Cache` 数据和内存数据一致：

- 1、如果数据不在 `Cache` 中，则直接将数据写入内存；
- 2、如果数据已经加载到 `Cache` 中，则不仅要将数据写入 `Cache`，还要将数据写入内存。


写直达的优点和缺点都很明显：

- 优点：每次读取操作不涉及对内存的写入操作，读取速度更快；
- 缺点：**每次写入操作都需要同时写入 Cache 和写入内存，在写入操作上失去了 CPU 高速缓存的价值，需要花费更多时间。**

![[Pasted image 20240707032404.png]]


## 1.2 写回策略(write back)


既然写直达策略在每次写入操作都会写内存，那么有没有什么办法可以减少写回内存的次数呢？这就是写回策略：

- 1、写回策略会在每个 `Cache` 块上增加一个 **“脏（Dirty）” 标记位** ，当一个 `Cache` 被标记为脏时，说明它的数据与内存数据是不一致的；
- 2、在写入操作时，我们只需要修改 `Cache` 块并将其标记为脏，而不需要写入内存；
- **3、那么，什么时候才将脏数据写回内存呢？—— 就发生在 Cache 块被替换出去的时候：**
    - 3.1 在写入操作中，如果目标内存块不在 `Cache` 中，*需要先将内存块数据读取到 `Cache` 中*。如果替换策略换出的旧 `Cache` 块是脏的，就会触发一次写回内存操作；
    - 3.2 在读取操作中，如果目标内存块不在 `Cache` 中，且替换策略换出的旧 `Cache` 块是脏的，就会触发一次写回内存操作；


写回策略只有当一个 `Cache` 数据将被替换出去时判断数据的状态，“清（未修改过，数据与内存一致）” 的 Cache 块不需要写回内存，“脏” 的 Cache 块才需要写回内存。这个策略能够减少写回内存的次数，性能会比写直达更高。当然，写回策略在读取的时候，有可能不是纯粹的读取了，因为还可能会触发一次脏 Cache 块的写入。

**这里还有一个设计：** 在目标内存块不在 Cache 中时，写直达策略会直接写入内存。而写回策略会先把数据读取到 Cache 中再修改 Cache 数据，这似乎有点多余？其实还是为了减少写回内存的次数。虽然在未命中时会增加一次读取操作，但后续重复的写入都能命中缓存。否则，只要一直不读取数据，写回策略的每次写入操作还是需要写入内存。


# 2 横向: 多核心 Cache 的一致性问题


在单核 `CPU` 中，我们通过写直达策略或写回策略保持了`Cache` 与内存的一致性。但是在多核 `CPU` 中，由于每个核心都有一份独占的 `Cache`，就会存在一个核心修改数据后，两个核心 `Cache` 不一致的问题。

举个例子：

- 1、`Core 1` 和 `Core 2` 读取了同一个内存块的数据，在两个 `Core` 都缓存了一份内存块的副本。此时，Cache 和内存块是一致的；
- 2、`Core 1` 执行内存写入操作：
    - 2.1 在写直达策略中，新数据会直接写回内存，此时，`Cache` 和内存块一致。但由于之前 `Core 2` 已经读过这块数据，所以 `Core 2` 缓存的数据还是旧的。此时，`Core 1` 和 `Core 2` 不一致；
    - 2.2 在写回策略中，新数据会延迟写回内存，此时 `Cache` 和内存块不一致。不管 `Core 2` 之前有没有读过这块数据，`Core 2` 的数据都是旧的。此时，`Core 1` 和 `Core 2` 不一致。
- 3、由于 `Core 2` 无法感知到 q 的写入操作，如果继续使用过时的数据，就会出现逻辑问题。
所以，我们需要一种机制，将多个核心的工作联合起来，共同保证多个核心下的 `Cache` 一致性，这就是缓存一致性机制。



## 2.1 写传播 & 事务串行化
缓存一致性机制需要解决的问题就是 2 点：

- **特性 1 - 写传播（Write Propagation）：** 每个 CPU 核心的写入操作，需要传播到其他 CPU 核心；
- **特性 2 - 事务串行化（Transaction Serialization）：** 各个 CPU 核心所有写入操作的顺序，在所有 CPU 核心看起来是一致。

## 2.2 总线嗅探 & 总线仲裁

写传播和事务串行化在 CPU 中是如何实现的呢？—— 此处隆重请出计算机总线系统。

- **写传播 - 总线嗅探：** 总线除了能在一个主模块和一个从模块之间传输数据，还支持一个主模块对多个从模块写入数据，这种操作就是广播。要实现写传播，其实就是将所有的读写操作广播到所有 CPU 核心，而其它 CPU 核心时刻监听总线上的广播，再修改本地的数据；
- **事务串行化 - 总线仲裁：** 总线的独占性要求同一时刻最多只有一个主模块占用总线，天然地会将所有核心对内存的读写操作串行化。如果多个核心同时发起总线事务，此时总线仲裁单元会对竞争做出仲裁，未获胜的事务只能等待获胜的事务处理完成后才能执行。

> **提示：** 写传播还有 “基于目录（Directory-base）” 的实现方案。


基于总线嗅探和总线仲裁，现代 CPU 逐渐形成了各种缓存一致性协议，例如 MESI 协议。

## 2.3 MESI 协议

MESI 协议其实是 CPU Cache 的有限状态机，一共有 4 个状态（MESI 就是状态的首字母）：

- **M（Modified，已修改）：** 表明 Cache 块被修改过，但未同步回内存；
- **E（Exclusive，独占）：** 表明 Cache 块被当前核心独占，而其它核心的同一个 Cache 块会失效；
- **S（Shared，共享）：** 表明 Cache 块被多个核心持有且都是有效的；
- **I（Invalidated，已失效）：** 表明 Cache 块的数据是过时的。

在 “独占” 和 “共享” 状态下，Cache 块的数据是 “清” 的，任何读取操作可以直接使用 Cache 数据；

在 “已失效” 和 “已修改” 状态下，Cache 块的数据是 “脏” 的，它们和内存的数据都可能不一致。在读取或写入 “已失效” 数据时，需要先将其它核心 “已修改” 的数据写回内存，再从内存读取；

在 “共享” 和 “已失效” 状态，核心没有获得 Cache 块的独占权（锁）。在修改数据时不能直接修改，而是要先向所有核心广播 **RFO（Request For Ownership）请求** ，将其它核心的 Cache 置为 “已失效”，等到获得回应 ACK 后才算获得 Cache 块的独占权。这个独占权这有点类似于开发语言层面的锁概念，在修改资源之前，需要先获取资源的锁；

在 “已修改” 和 “独占” 状态下，核心已经获得了 Cache 块的独占权（锁）。在修改数据时不需要向总线发送广播，能够减轻总线的通信压力。

事实上，完整的 MESI 协议更复杂，但我们没必要记得这么细。我们只需要记住最关键的 2 点：

- **关键 1 - 阻止同时有多个核心修改的共享数据：** 当一个 CPU 核心要求修改数据时，会先广播 RFO 请求获得 Cache 块的所有权，并将其它 CPU 核心中对应的 Cache 块置为已失效状态；
- **关键 2 - 延迟回写：** 只有在需要的时候才将数据写回内存，当一个 CPU 核心要求访问已失效状态的 Cache 块时，会先要求其它核心先将数据写回内存，再从内存读取。

> **提示：** MESI 协议在 MSI 的基础上增加了 E（独占）状态，以减少只有一份缓存的写操作造成的总线通信。

MESI 协议有一个非常 nice 的在线体验网站，你可以对照文章内容，在网站上操作指令区，并观察内存和缓存的数据和状态变化。网站地址：https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESI.htm

![[Pasted image 20240707115725.png]]


#### 2.3.1.1 **4.4 写缓冲区 & 失效队列**

MESI 协议保证了 Cache 的一致性，但完全地遵循协议会影响性能。**因此，现代的 CPU 会在增加写缓冲区和失效队列将 MESI 协议的请求异步化，以提高并行度：**

- **写缓冲区（Store Buffer）**

由于在写入操作之前，CPU 核心 1 需要先广播 RFO 请求获得独占权，在其它核心回应 ACK 之前，当前核心只能空等待，这对 CPU 资源是一种浪费。因此，现代 CPU 会采用 “写缓冲区” 机制：写入指令放到写缓冲区后并发送 RFO 请求后，CPU 就可以去执行其它任务，等收到 ACK 后再将写入操作写到 Cache 上。

- **失效队列（Invalidation Queue）**

由于其他核心在收到 RFO 请求时，需要及时回应 ACK。但如果核心很忙不能及时回复，就会造成发送 RFO 请求的核心在等待 ACK。因此，现代 CPU 会采用 “失效队列” 机制：先把其它核心发过来的 RFO 请求放到失效队列，然后直接返回 ACK，等当前核心处理完任务后再去处理失效队列中的失效请求。

1.6、虚拟cache和物理cache
1.6.1、物理cache
当处理器查询MMU和TLB得到物理地址之后，只用物理地址去查询高速缓存，我们称为物理高速缓存。使用物理高速缓存的缺点就是处理器在查询MMU和TLB之后才能够访问高速缓存，增加了延迟。

1.6.2、虚拟cache
CPU使用虚拟地址来寻址高速缓存，我们成为虚拟高速缓存。处理器在寻址时，首先把虚拟地址发送到高速缓存中，若在高速缓存里找到需要的数据，那么就不再需要访问TLB和物理内存。处理器在寻址时，首先把虚拟地址发送到高速缓存中，若在高速缓存里找到需要的数据，那么就不再需要访问TLB和物理内存。

1.7、cache的分类
在查询cache的时候使用了index和tag，那么查询cache时用的是虚拟地址还是物理地址的index？当找到cache组的时候，我们用的是虚拟地址还是物理地址的tag来匹配cache line呢？

cache可以设计成通过虚拟地址来访问，也可以设计成通过物理地址来访问，这个在CPU设计时就确定下来了，并且对cache的管理有很大的影响。cache可以分成以下三类：

VIVT(Virtual Index Virtual Tag) : 使用虚拟地址的index和tag，相当于虚拟高速缓存
PIPT(Physical Index Physical Tag) : 使用物理地址的index和tag，相当于物理高速缓存
VIPT(Virtual Index Physical Tag) : 使用虚拟地址的index和物理地址的tag
在早期的ARM处理器中采用的是VIVT的方式，不经过MMU的翻译，直接使用虚拟地址的index和tag来查找cache line，这种方式会导致cache别人的问题。也就是一个物理地址的内容可能出现在多个cache line中，当系统改变了虚拟地址到物理地址的映射时，需要清洗和无效这些cache，导致系统性能下降

1.7.1、VIPT的工作原理
现在很多cortex系列的处理器的L1 data cache采用VIPT方式，即CPU输出的虚拟地址同时会发送到TLB/MMU单元进行地址翻译，以及在高速缓存中进行索引和查询高速缓存。在TLB/MMU单元里，会把虚拟页帧号（VPN）翻译成物理页帧号（PFN），与此同时，虚拟地址的索引域和偏移会用来查询高速缓存。这样高速缓存和TLB/MMU可以同时工作，当TLB/MMU完成地址翻译后，再用物理标记域来匹配高速缓存行。采用VIPT方式的好处之一是在多任务操作系统中，修改了虚拟地址到物理地址映射关系，不需要把相应的高速缓存进行无效操作。

1.7.2、VIVT（虚拟高速缓存）造成的重名同名问题
重名问题：（不同虚拟地址指向相同的物理地址）
重名问题是怎么产生的呢？我们知道，在操作系统中，多个不同的虚拟地址有可能映射相同的物理地址。由于采用VIPI架构，那么这些不同的虚拟地址会占用高速缓存中不同的高速缓存行（cache line），但是它们对应的是相同的物理地址，这样会引发问题：一是浪费了高速缓存空间，造成高速缓存等效容量的减少，减低整体性能；第二，在执行写操作的时候，只更新其中一个虚拟地址对应的高速缓存，而其他虚拟地址对应的高速缓存并没有更新。那么处理器访问其他虚拟地址可能得到旧数据。

举个例子，比如我们的cache使用的是VIPI，VA1映射到PA，VA2也映射到PA，那么在cache中有可能同时缓存了VA1和VA2两个虚拟地址。当程序往VA1虚拟地址写入数据的时候，PA的内容会被更改，但是虚拟地址VA2对应的cache里面还保存着旧数据，当CPU去读取VA2的值时，读到就是旧地址。一个物理地址在VIPI中就保存了两份数据，这样会产生歧义。

同名问题：（相同的虚拟地址指向不同的物理地址）
同名问题是怎么产生的呢？ 同名问题指的是相同的虚拟地址对应着不同的物理地址。因为操作系统中不同的进程会存在很多相同的虚拟地址，而这些相同的虚拟地址在经过MMU转换后得到不同的物理地址，这样就产生了同名问题。

同名问题最常出现的地方就是进程切换。当一个进程切换到另一个进程时，新进程使用虚拟地址来访问cache的话，新进程会访问到旧进程遗留下来的高速缓存，这些高速缓存数据对于新进程来说是错误和没用的，解决办法就是在进程切换时把旧进程遗留下来的高速缓存都设置为无效，这样就能保证新进程执行时得到一个干净的虚拟高速缓存。同样，TLB也需要设置为无效，因为新进程在切换后得到一个旧进程使用的TLB，里面存放了旧进程和虚拟地址到物理地址的转换结果。

重名问题实际上是多个虚拟地址映射到同一个物理地址引发的歧义问题，而同名问题是一个虚拟地址可能因为进程切换等原因映射到不同的物理地址而引发的问题。

1.7.3、VIPT的重名问题
采用VIPT方式也有可能导致高速缓存别人的问题。

使用虚拟地址的index来查找高速缓存的cache line，这时有可能导致多个高速缓存组映射到同一个物理地址上。
以Linux内核为例，它是以4KB大小为一个页面进行管理的，那么对于一个页来说，虚拟地址和物理地址的低